# -*- coding: utf-8 -*-
"""
This file is part of pyCMBS. (c) 2012-2014
For COPYING and LICENSE details, please refer to the file
COPYRIGHT.md
"""

from cdo import Cdo

import matplotlib
matplotlib.rcParams['backend'] = 'Agg'

from matplotlib.font_manager import FontProperties
import sys
import os
from datetime import datetime

import matplotlib.pyplot as plt
import pylab as pl
import pylab
import numpy as np
from dateutil.rrule import rrule
from dateutil.rrule import MONTHLY

from pycmbs.diagnostic import PatternCorrelation, RegionalAnalysis, Diagnostic
from pycmbs.plots import GlobalMeanPlot, map_season, map_difference, ReichlerPlot, HstackTimeseries
from pycmbs.mapping import map_plot
from pycmbs.data import Data
from pycmbs.benchmarking.utils import get_T63_landseamask, get_temporary_directory


def preprocess_seasonal_data(raw_file, interval=None, themask=None,
                             force=False, obs_var=None, label='',
                             shift_lon=None,
                             start_date=None, stop_date=None,
                             target_grid='t63grid',
                             interpolation_method='remapcon'):
    """
    This subroutine performs pre-processing of some raw data file. It does

    1) generate monthly timeseries
    2) generate seasonal timeseries
    3) remaps data to T63 grid
    4) calculates standard deviation and number of valid data
    5) returns seasonal/monthly climatology as well as monthly mean raw data

    ALL generated data will be stored in temporary data directory

    @param raw_file: name of original data file to be processed
    @type raw_file: str

    @param interval: [season,monthly]
    @type interval: str

    @param force: force caluclations
    @type force: bool

    @param themask: mask to be applied to the data (default=None)
    @type themask: numpy bool array or Data

    @param obs_var: variable to analyze
    @type obs_var: str

    @param start_date: date where the observations should start
    @type start_date: datetime.datetime

    @param stop_date: date where the observations should stop
    @type stop_date: datetime.datetime

    @param target_grid: target grid specification for remapping. This can be either a string specifying the grid following the cdo conventions or a file which contains the grid already
    @type target_grid: str

    """

    sys.stdout.write(' *** Preprocessing ' + raw_file + '\n')

    if obs_var is None:
        raise ValueError('Name of variable to be processed needs to be specified!')
    if shift_lon is None:
        raise ValueError('Lon shift parameter needs to be specified!')

    # PREPROCESSING of observational data  ---
    cdo = Cdo()

    # 1) generate monthly mean file projected to T63
    obs_mon_file = get_temporary_directory() + os.path.basename(raw_file)

    # construct string for seldate; it is assumed that it was already checked before that start_date,stop_date are valid datetime objects!

    if (start_date is not None) and (stop_date is not None):
        print 'Temporal subsetting for ' + raw_file + ' will be performed! ', start_date, stop_date
        seldate_str = ' -seldate,' + str(start_date)[0: 10] + ',' + str(stop_date)[0: 10]
        obs_mon_file = obs_mon_file[:-3] + '_' + str(start_date)[0: 10] + '_' + str(stop_date)[0: 10] + '_monmean.nc'
    else:
        seldate_str = ''
        obs_mon_file = obs_mon_file[:-3] + '_monmean.nc'

    cdo.monmean(options='-f nc', output=obs_mon_file,
                input='-' + interpolation_method + ',' + target_grid + seldate_str + ' ' + raw_file, force=force)

    # 2) generate monthly mean or seasonal mean climatology as well as standard deviation
    if interval == 'monthly':
        obs_ymonmean_file = obs_mon_file[:-3] + '_ymonmean.nc'
        obs_ymonstd_file = obs_mon_file[:-3] + '_ymonstd.nc'
        obs_ymonsum_file = obs_mon_file[:-3] + '_ymonsum.nc'
        obs_ymonN_file = obs_mon_file[:-3] + '_ymonN.nc'
        cdo.ymonmean(options='-f nc -b 32', output=obs_ymonmean_file, input=obs_mon_file, force=force)
        cdo.ymonsum(options='-f nc -b 32', output=obs_ymonsum_file, input=obs_mon_file, force=force)
        cdo.ymonstd(options='-f nc -b 32', output=obs_ymonstd_file, input=obs_mon_file, force=force)
        cdo.div(options='-f nc -b 32', output=obs_ymonN_file, input=obs_ymonsum_file + ' ' + obs_ymonmean_file,
                force=force)  # number of samples
        time_cycle = 12
    elif interval == 'season':
        obs_ymonmean_file = obs_mon_file[:-3] + '_yseasmean.nc'
        obs_ymonstd_file = obs_mon_file[:-3] + '_yseasstd.nc'
        obs_ymonsum_file = obs_mon_file[:-3] + '_yseassum.nc'
        obs_ymonN_file = obs_mon_file[:-3] + '_yseasN.nc'
        cdo.yseasmean(options='-f nc -b 32', output=obs_ymonmean_file, input=obs_mon_file, force=force)
        cdo.yseassum(options='-f nc -b 32', output=obs_ymonsum_file, input=obs_mon_file, force=force)
        cdo.yseasstd(options='-f nc -b 32', output=obs_ymonstd_file, input=obs_mon_file, force=force)
        cdo.div(options='-f nc -b 32', output=obs_ymonN_file, input=obs_ymonsum_file + ' ' + obs_ymonmean_file,
                force=force)  # number of samples
        time_cycle = 4
    else:
        print interval
        raise ValueError('Unknown temporal interval. Can not perform preprocessing! ')

    #--- READ DATA ---
    obs = Data(obs_ymonmean_file, obs_var, read=True, label=label,
               lat_name='lat', lon_name='lon', shift_lon=shift_lon,
               time_cycle=time_cycle)
    obs_std = Data(obs_ymonstd_file, obs_var, read=True,
                   label=label + ' std', lat_name='lat', lon_name='lon',
                   shift_lon=shift_lon, time_cycle=time_cycle)
    obs.std = obs_std.data.copy()
    del obs_std
    obs_N = Data(obs_ymonN_file, obs_var, read=True,
                 label=label + ' N', unit='-', lat_name='lat',
                 lon_name='lon',
                 shift_lon=shift_lon, time_cycle=time_cycle)
    obs.n = obs_N.data.copy()
    del obs_N

    # sort climatology to be sure that it starts always with January
    obs.adjust_time(year=1700, day=15)  # set arbitrary time for climatology
    obs.timsort()

    #/// read monthly data (needed for global means and hovmoeller plots) ///
    obs_monthly = Data(obs_mon_file, obs_var, read=True, label=label,
                       lat_name='lat', lon_name='lon',
                       shift_lon=shift_lon)  # ,mask=ls_mask.data.data)

    #try to ensure really monthly increasing time series
    if hasattr(obs_monthly, 'time_cycle'):
        if obs_monthly.time_cycle != 12:
            obs_monthly._pad_timeseries(fill_value=obs_monthly.fill_value)
    if obs_monthly.time_cycle != 12:
        raise ValueError('Timecycle could still not be set!!! %s' % obs_mon_file)

    #/// center dates of months
    obs_monthly.adjust_time(day=15)
    obs.adjust_time(day=15)

    if themask is not None:
        obs._apply_mask(themask)
        obs_monthly._apply_mask(themask)

    return obs, obs_monthly


#///////////////////////////////////////////////////////////////////////
# ANALYSIS SECTION
#///////////////////////////////////////////////////////////////////////

#-----------------------------------------------------------------------------------------------------------------------

def seaice_concentration_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False,
                                  report=None, plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='seaice_concentration', regions=regions)


def seaice_extent_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                           plot_options=None, regions=None):
    header = 'The sea ice extent is calculated based on sea-ice concentration. It is defined by all grid cells which have a sea ice concentration larger than 15 percent.'
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='seaice_extent', regions=regions, sectionheader=header)

#-----------------------------------------------------------------------------------------------------------------------


def evaporation_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                         plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='evap', regions=regions)

#-----------------------------------------------------------------------------------------------------------------------


def rainfall_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                      plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='rain', regions=regions)


def wind_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                  plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='wind', regions=regions)


def twpa_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                  plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='twpa', regions=regions)


def wvpa_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                  plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='wvpa', regions=regions)


def hair_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                  plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='hair', regions=regions)


def late_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                  plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='late', regions=regions)


def budg_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                  plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='budg', regions=regions)


def gpp_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                 plot_options=None, regions=None):
#    main_analysis(model_list,interval=interval,GP=GP,shift_lon=shift_lon,use_basemap=use_basemap,report = report,plot_options=plot_options,actvar='gpp',regions=regions)
    beer_analysis(model_list, interval="season", GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options)


def cfc_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                 plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='cfc', regions=regions)


def nsJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='nsJch', regions=regions)


def acJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='acJch', regions=regions)


def cuJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='cuJch', regions=regions)


def cbJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='cbJch', regions=regions)


def stJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='stJch', regions=regions)


def ciJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='ciJch', regions=regions)


def asJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='asJch', regions=regions)


def csJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='csJch', regions=regions)


def scJch_analysis(model_list, interval='season', GP=None, shift_lon=False, use_basemap=False, report=None,
                   plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon, use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='scJch', regions=regions)

#=======================================================================
# GENERIC - start
#=======================================================================


def generic_analysis(plot_options, model_list, obs_type, obs_name,
                     GP=None, GM=None, shift_lon=False,
                     use_basemap=False, report=None, interval=None,
                     regions=None, GM_HT_clim=None):
    """
    function for performing common analysis actions
    it is not a parameter specific function
    use it as a template for specific analysis

    Parameters
    ----------
    plot_options : PlotOptions
        class of PlotOptions which specifies the
        options how plots shall look like!
    model_list : list
        list of Model objects
    obs_type : str
        type of observation (variable to be analyzed);
        needs to be consistent with the variables specified in main.py and
        the config file (e.g. 'sis','rain')
    obs_name : str
        name of observational record as specified in the
        INI file e.g. HOAPS, CMSAF ...
    GP : GlecklerPlot
        class of GlecklerPlot, used as global handler to collect
        statistical results over different variables
    GM : GlobalMeanPlot
        collection of all releavan data for generating Global mean plot
    shift_lon : bool
        shift longitudes if True
    use_basemap : bool
        project data in plots
    report : Report
        handler to report generator
    interval : str
        ['monthly', 'seasonal']
    GM_HT_clim : HstackTimeseries
        handler to global mean plots using class for stacked timeseries
    """

    # GENERAL CHECKS
    if interval not in ['monthly', 'season']:
        raise ValueError('invalid interval in generic_analysis() %s' % interval)

    if obs_type not in plot_options.options.keys():
        raise ValueError('No plot options available for the following data: %s' % obs_type)

    if report is None:
        raise ValueError("Report option was not enabled")

    # PLOT OPTIONS
    # gives a dictionary with all the options for the current variable
    local_plot_options = plot_options.options[obs_type]

    if 'OPTIONS' not in local_plot_options.keys():
        raise ValueError('No OPTIONS specified for analysis of variable %s' % obs_type)
    if obs_name not in local_plot_options.keys():
        print 'Observational data not existing: ', obs_name, ' ... skipping analysis'
        return

    #... now everything should be fine and the plot options can be assigned locally

    #//////////////////////////////////////////////////////////////////
    # plot options which are SPECIFIC to observational data sets
    for_report = local_plot_options[obs_name]['add_to_report']  # add a certain observational dataset to report
    if not for_report:
        print '   The following data will not be included in the report as option for reporting is not set: ' + obs_name + ' ' + obs_type
        return

    obs_raw = local_plot_options[obs_name]['obs_file']
    obs_var = local_plot_options[obs_name]['obs_var']
    gleckler_pos = local_plot_options[obs_name]['gleckler_position']

    if 'start' in local_plot_options['OPTIONS'].keys():
        obs_start = local_plot_options['OPTIONS']['start']
        if isinstance(obs_start, datetime):
            pass
        else:
            try:
                obs_start = pl.num2date(pl.datestr2num(obs_start))
            except:
                print 'WARNING: INVALID start time: ', obs_start, ' SETTING to NONE!'
                obs_start = None
    else:
        obs_start = None

    if 'stop' in local_plot_options['OPTIONS'].keys():
        obs_stop = local_plot_options['OPTIONS']['stop']
        if isinstance(obs_stop, datetime):
            pass
        else:
            try:
                obs_stop = pl.num2date(pl.datestr2num(obs_stop))
            except:
                print 'WARNING: INVALID stop time: ', obs_stop, ' SETTING to NONE!'
                obs_stop = None
    else:
        obs_stop = None

    if 'scale_data' in local_plot_options[obs_name].keys():
        obs_scale_data = local_plot_options[obs_name]['scale_data']
    else:
        obs_scale_data = 1.
    if 'add_offset' in local_plot_options[obs_name].keys():
        obs_add_offset = local_plot_options[obs_name]['add_offset']
    else:
        obs_add_offset = 0.
    if 'valid_mask' in local_plot_options[obs_name].keys():
        valid_mask = local_plot_options[obs_name]['valid_mask']
    else:
        valid_mask = 'global'
    valid_mask = valid_mask.lower()

    #//////////////////////////////////////////////////////////////////
    #--- plot options which are the same for all observational datasets
    cticks = local_plot_options['OPTIONS']['cticks']
    f_mapdifference = local_plot_options['OPTIONS']['map_difference']
    f_mapseasons = local_plot_options['OPTIONS']['map_seasons']
    f_mapseason_difference = local_plot_options['OPTIONS']['map_season_difference']
    f_preprocess = local_plot_options['OPTIONS']['preprocess']
    f_reichler = local_plot_options['OPTIONS']['reichler_plot']
    f_gleckler = local_plot_options['OPTIONS']['gleckler_plot']
    f_hovmoeller = local_plot_options['OPTIONS']['hovmoeller_plot']
    f_regional_analysis = local_plot_options['OPTIONS']['regional_analysis']
    f_globalmeanplot = local_plot_options['OPTIONS']['global_mean']
    f_pattern_correlation = local_plot_options['OPTIONS']['pattern_correlation']
    interpolation_method = local_plot_options['OPTIONS']['interpolation']
    targetgrid = local_plot_options['OPTIONS']['targetgrid']
    projection = local_plot_options['OPTIONS']['projection']
    theunit = local_plot_options['OPTIONS']['units']

    if regions is None:
        f_regional_analysis = False

    if 'nclasses' in local_plot_options['OPTIONS'].keys():
        nclasses = int(local_plot_options['OPTIONS']['nclasses'])
    else:
        nclasses = 6

    if 'vmin' in local_plot_options['OPTIONS'].keys():
        vmin = local_plot_options['OPTIONS']['vmin']
    else:
        vmin = None

    if 'vmax' in local_plot_options['OPTIONS'].keys():
        vmax = local_plot_options['OPTIONS']['vmax']
    else:
        vmax = None

    if 'dmin' in local_plot_options['OPTIONS'].keys():
        dmin = local_plot_options['OPTIONS']['dmin']
    else:
        dmin = None
    if 'dmax' in local_plot_options['OPTIONS'].keys():
        dmax = local_plot_options['OPTIONS']['dmax']
    else:
        dmax = None

    if 'cticks_diff' in local_plot_options['OPTIONS'].keys():
        cticks_diff = local_plot_options['OPTIONS']['cticks_diff']
    else:
        cticks_diff = None

    if 'cticks_rdiff' in local_plot_options['OPTIONS'].keys():
        cticks_rdiff = local_plot_options['OPTIONS']['cticks_rdiff']
    else:
        cticks_rdiff = None

    m_data_org = obs_type + '_org'  # name of original data field

    #/// land sea mask (options: land,ocean, global for parameter area)
    # mask_antarctica masks everything below 60 degrees S.
    # here we only mask Antarctica, if only LAND points shall be used
    if valid_mask == 'land':
        mask_antarctica = True
    elif valid_mask == 'ocean':
        mask_antarctica = False
    else:
        mask_antarctica = False

    if targetgrid == 't63grid':
        ls_mask = get_T63_landseamask(shift_lon, area=valid_mask, mask_antarctica=mask_antarctica)
    else:
        ls_mask = get_generic_landseamask(shift_lon, area=valid_mask, target_grid=targetgrid,
                                          mask_antarctica=mask_antarctica)

    #####################################################################
    # OBSERVATION DATA PREPROCESSING
    #####################################################################
    #if f_preprocess == True: #always do preprocessing
    #obs_orig corresponds to the climatological mean field
    #obs_monthly is the monthly mean timeseries of the whole record (or seasonal mean)
    obs_orig, obs_monthly = preprocess_seasonal_data(obs_raw, interval=interval, themask=ls_mask,
                                                     force=False, obs_var=obs_var, label=obs_name,
                                                     shift_lon=shift_lon, start_date=obs_start, stop_date=obs_stop,
                                                     interpolation_method=interpolation_method,
                                                     target_grid=targetgrid)

    # rescale data following CF conventions
    obs_orig.mulc(obs_scale_data, copy=False)
    obs_monthly.mulc(obs_scale_data, copy=False)
    obs_orig.addc(obs_add_offset, copy=False)
    obs_monthly.addc(obs_add_offset, copy=False)

    # set unit
    obs_orig.unit = theunit
    obs_monthly.unit = theunit

    #### IDENTIFY AREAS WHERE THERE IS AT LEAST SOME VALID DATA ####
    valid_obs = ((~obs_orig.data.mask).sum(axis=0)) > 0  # find all data where there is at least SOME data

    #~ plt.close('all')
    #~ plt.imshow(valid_obs)
    #~ plt.show()
#~
    #~ stop

    obs_orig._apply_mask(valid_obs)
    obs_monthly._apply_mask(valid_obs)

    def mask_seaice_extent(x, msk):
        tmpmsk = x.data > 15.
        x.data.mask[:, :, :] = False  # set all to false to be able to put entire ocean to zero
        x.data[:, :, :] = 0.
        x.data[tmpmsk] = 1.
        x._apply_mask(msk)
        return x

    if obs_type == 'seaice_extent':
        stat_type = 'sum'  # show area weighted sum as statistic
        obs_orig = mask_seaice_extent(obs_orig, ls_mask)
        obs_monthly = mask_seaice_extent(obs_monthly, ls_mask)
        obs_orig._apply_mask(valid_obs)
        obs_monthly._apply_mask(valid_obs)
    else:
        stat_type = 'mean'

    #####################################################################
    # PLOTS
    #####################################################################
    # initialize Reichler plot
    if f_reichler is True:
        Rplot = ReichlerPlot()  # needed here, as it might include multiple model results

    if f_pattern_correlation:  # init plot for PatternCorrelation
        PC_plot = HstackTimeseries()

    if f_globalmeanplot:
        if GM is None:
            fG = plt.figure()
            axg = fG.add_subplot(211)
            axg1 = fG.add_subplot(212)
            GM = GlobalMeanPlot(ax=axg, ax1=axg1, climatology=True)  # global mean plot

        else:
            if isinstance(GM, GlobalMeanPlot):
                pass
            else:
                raise ValueError('Global mean variable GM has invalid object type')
    else:
        GM = None

    if f_globalmeanplot:
        if GM_HT_clim is None:
            GM_HT_clim = HstackTimeseries()
        else:
            pass
    else:
        GM_HT_clim = None

    # global mean plot of observational data
    if GM is not None:
        GM.plot(obs_monthly, linestyle='--', show_std=False, group='observations', stat_type=stat_type)

    if GM_HT_clim is not None:
        # alternative way of plotting timeseries using Hstacktimeseries
        tmp = obs_monthly.get_climatology(return_object=True)
        GM_HT_clim.add_data(tmp.fldmean(), 'obs:' + obs_monthly.label)  # global mean climatology
        del tmp

    if f_mapseasons is True:  # seasonal mean plot for observations

        f_season = map_season(obs_orig, use_basemap=use_basemap,
                              cmap_data='jet',
                              show_zonal=False, zonal_timmean=True,
                              nclasses=nclasses,
                              vmin=vmin, vmax=vmax, cticks=cticks,
                              proj=projection, stat_type=stat_type,
                              show_stat=True, drawparallels=False,
                              titlefontsize=8)

        if len(obs_orig.data) == 4:
            report.figure(f_season, caption='Seasonal mean ' + obs_name)
        else:
            report.figure(f_season, caption='Monthly mean ' + obs_name)
        plt.close(f_season.number)

    ####################################################################################################################
    # MAIN LIST OVER MODELS
    ####################################################################################################################

    for model in model_list:
        sys.stdout.write('\n *** %s Analysis of model: ' % (obs_type.upper()) + model.name + "\n")

        if model.variables[obs_type] is None:
            sys.stdout.write('\n *** WARNING: No processing for %s possible for model (likely missing data!): ' % (
                obs_type) + model.name + "\n")
            continue
        else:
            model_data = model.variables[obs_type].copy()

        model_data.unit = theunit

        ### todo: make this more flexible !!!
        if obs_type == 'seaice_extent':
            model_data = mask_seaice_extent(model_data, ls_mask)

        # land/sea mask
        if ls_mask is not None:
            actmask = (ls_mask.data.mask) & (valid_obs)
        else:
            actmask = valid_obs
        model_data._apply_mask(actmask)

        GP.add_model(model._unique_name)  # register model name in GlecklerPlot

        if for_report is True:
            #/// report results
            sys.stdout.write('\n *** Making report figures. \n')
            report.subsubsection(model._unique_name)

        if GM is not None:
            if model.name == 'mean-model':
                pass
            else:
                if m_data_org in model.variables.keys():
                    if model.variables[m_data_org][2] is None:  # invalid data for mean_model --> skip
                        pass
                    else:
                        tmp = model.variables[m_data_org][2]
                        tmp._apply_mask(actmask)
                        GM.plot(tmp, label=model._unique_name, show_std=False,
                                group='models')  # (time,meandata) replace rain_org with data_org
                        del tmp

        if GM_HT_clim is not None:
            if model.name == 'mean-model':
                pass
            else:
                tmp = model.variables[m_data_org][2]
                tmp._apply_mask(actmask)
                GM_HT_clim.add_data(tmp.get_climatology(return_object=True, ensure_start_first=True).fldmean(), model.name, raise_duplicate_error=False)

        if model_data is None:
            sys.stdout.write('Data not existing for model %s' % model.name)
            continue

        if model_data.data.shape != obs_orig.data.shape:
            print 'Inconsistent geometries'  # add here parameter name
            print 'Model: ', model_data.data.shape
            print 'Observation: ', obs_orig.data.shape
            raise ValueError("Invalid geometries")

        if f_mapdifference is True:
            sys.stdout.write('\n *** Map difference plotting. \n')
            # generate difference map
            savegraphics_prefix = os.environ['PYCMBS_OUTPUTDIR'] + obs_orig._get_label() + '___' + model_data._get_label() + '.' + os.environ['PYCMBS_OUTPUTFORMAT']
            f_dif = map_difference(model_data, obs_orig,
                                   nclasses=nclasses,
                                   use_basemap=use_basemap,
                                   show_zonal=False, zonal_timmean=True,
                                   dmin=dmin, dmax=dmax, vmin=vmin,
                                   vmax=vmax, cticks=cticks,
                                   proj=projection, stat_type=stat_type,
                                   show_stat=True, drawparallels=False,
                                   colorbar_orientation='horizontal',
                                   savegraphics_prefix=savegraphics_prefix,
                                   cticks_diff=cticks_diff,
                                   cticks_rdiff=cticks_rdiff)
            report.figure(f_dif, caption='Temporal mean fields (top) and absolute and relative differences (bottom)')
            plt.close(f_dif.number)
            del f_dif

        f_compare_timeseries = False  # todo
        if f_compare_timeseries is True:
            """
            compare timeseries of two datasets
            1) apply same mask
            2) calculate regional statistics based on a predefined mask
            3) report back figure with timeseries
            """

            #--- in general it would be good to define a mask based on predefined regions.
            # in general, such a RegionalAnalysis is already implemented at 80% in pyCMBS, but not finished yet
            #I therefore propose to just use simple latitudinal bands here for the EvaClimod purposes at the moment

            themask = np.ones(model_data.timmean().shape)  # generate a mask with proper geometry

            #1) lat-band 1
            tmp = (model_data.lat > 30.)  # extratropic 1
            themask[tmp] = 2.
            del tmp

            tmp = (model_data.lat < -30.)  # extratropic 2
            themask[tmp] = 3.
            del tmp

            fig_comp_time = time_series_regional_analysis(model_data, obs_orig, themask)
            report.figure(fig_comp_time, caption='Here your user defined caption ... Have fun')
            pl.close(fig_comp_time.number)

            del fig_comp_time

        if f_mapseasons is True:
            sys.stdout.write('\n *** Seasonal maps plotting\n')

            # seasonal map
            f_season = map_season(model_data, use_basemap=use_basemap,
                                  cmap_data='jet',
                                  show_zonal=False, zonal_timmean=True,
                                  nclasses=nclasses,
                                  vmin=vmin, vmax=vmax, cticks=cticks,
                                  proj=projection, stat_type=stat_type,
                                  show_stat=True,
                                  drawparallels=False, titlefontsize=8)
            if len(model_data.data) == 4:
                report.figure(f_season, caption='Seasonal mean climatology for ' + model.name)
            else:
                report.figure(f_season, caption='Monthly mean climatology for ' + model.name)
            plt.close(f_season.number)
            del f_season

        if f_mapseason_difference:
            # generate seasonal plot of difference
            f_season_dif = map_season(model_data.sub(obs_orig),
                                      use_basemap=use_basemap,
                                      cmap_data='RdBu_r',
                                      show_zonal=False,
                                      zonal_timmean=True,
                                      nclasses=nclasses,
                                      vmin=dmin, vmax=dmax,
                                      proj=projection,
                                      stat_type=stat_type,
                                      show_stat=True,
                                      drawparallels=False,
                                      cticks=[cticks_diff[0],
                                              cticks_diff[-1]],
                                      titlefontsize=10)

            if len(model_data.data) == 4:
                report.figure(f_season_dif,
                              caption='Seasonal mean climatology of difference between '
                                      + model.name.upper() + ' and ' + obs_orig.label.upper())
            else:
                report.figure(f_season_dif,
                              caption='Monthly mean climatology of difference between '
                                      + model.name.upper() + ' and ' + obs_orig.label.upper())
            plt.close(f_season_dif.number)
            del f_season_dif

        if f_pattern_correlation:
            # perform pattern correlation
            PC = PatternCorrelation(obs_orig, model_data)
            PC._correlate()
            # store data for final plot

            print len(model_list)
            print model_data.label
            PC_plot.add_data(PC.r_value, model.name, raise_duplicate_error=True)
            del PC

        if f_hovmoeller is True:
            print('    Doing Hovmoeller plot ...')
            f_hov = plt.figure(figsize=(8, 12))
            ax1 = f_hov.add_subplot(4, 1, 1)
            ax2 = f_hov.add_subplot(4, 1, 2)
            ax3 = f_hov.add_subplot(4, 1, 3)
            ax4 = f_hov.add_subplot(4, 1, 4)

            s_start_time = '1979-01-01'  # todo: use periods specified in options !!!!
            s_stop_time = '2012-12-31'
            start_time = pylab.num2date(pylab.datestr2num(s_start_time))
            stop_time = pylab.num2date(pylab.datestr2num(s_stop_time))

            # generate a reference monthly timeseries (datetime)
            tref = np.asarray(
                rrule(MONTHLY, dtstart=start_time).between(start_time, stop_time, inc=True))  # monthly timeseries

            ####################################################
            # HOVMOELLER PLOT FOR MODEL
            ####################################################

            # perform temporal subsetting and interpolation for hovmoeller plot
            tmp = model.variables[obs_type + '_org'][2]
            if tmp is not None:
                tmp = tmp.interp_time(tref)
                if ls_mask is not None:
                    tmp._apply_mask(ls_mask)
                hov_model = hovmoeller(tmp.date, None, rescaley=20, rescalex=20)
                hov_model.plot(climits=[vmin, vmax], input=tmp, xtickrotation=90, cmap='jet', ax=ax1, showcolorbar=True,
                               showxticks=False)

                hov_model.hov = None
                hov_model.plot(climits=[dmin, dmax], input=tmp.get_deseasonalized_anomaly(base='current'),
                               xtickrotation=90, cmap='RdBu_r', ax=ax2, showcolorbar=True, showxticks=True)
                del hov_model, tmp

            ####################################################
            # HOVMOELLER PLOT FOR OBSERVATIONS
            ####################################################
            tmp = obs_monthly.copy()
            if tmp is not None:
                tmp = tmp.interp_time(pl.date2num(tref))
                if ls_mask is not None:
                    tmp._apply_mask(ls_mask)

                hov_obs = hovmoeller(tmp.date, None, rescaley=20,
                                     rescalex=20)
                hov_obs.plot(climits=[vmin, vmax], input=tmp,
                             xtickrotation=90, cmap='jet', ax=ax3,
                             showcolorbar=True,
                             showxticks=False)

                hov_obs.hov = None
                hov_obs.plot(climits=[dmin, dmax],
                             input=tmp.get_deseasonalized_anomaly(base='current'),
                             xtickrotation=90, cmap='RdBu_r', ax=ax4,
                             showcolorbar=True)
                del hov_obs, tmp

            report.figure(f_hov,
                          caption='Time-latitude diagram of SIS and SIS anomalies (top: ' + model.name
                                  + ', bottom: ' + obs_name.upper() + ')')
            pl.close(f_hov.number)
            del f_hov

        # Perform regional analysis
        if f_regional_analysis:

            #some dummy region
            #regions_for_stat = Data(None,None)
            #regions_for_stat.data = (np.random.random(obs_orig.shape[1:3])*5. + 1.).astype('int')

            region_file = local_plot_options['OPTIONS']['region_file']
            region_file_varname = local_plot_options['OPTIONS']['region_file_varname']
            # user needs to ensure that geometry matches!
            regions_for_stat = Data(region_file, region_file_varname, read=True)

            REGSTAT = RegionalAnalysis(obs_orig, model_data, regions_for_stat)
            REGSTAT.calculate()  # after that we have the regional statistics already calculated for the current model

            # save results
            sprefix = obs_type.upper() + '_' + obs_name.upper() + '_' + model._unique_name
            REGSTAT.save(prefix=sprefix, dir=report.outdir, format='pkl')
            REGSTAT.save(prefix=sprefix, dir=report.outdir, format='txt')

            del REGSTAT

        if f_reichler is True:
            sys.stdout.write('\n *** Computing diagnostics (Reichler index). \n')
            Diag = Diagnostic(obs_orig, model_data)
            e2 = Diag.calc_reichler_index()
            Rplot.add(e2, model_data.label, color='red')

        if f_gleckler is True:
            sys.stdout.write('\n *** Glecker plot. \n')
            e2a = GP.calc_index(obs_orig, model_data, model, obs_type)
            GP.add_data(obs_type, model._unique_name, e2a, pos=gleckler_pos)

    # final plotting
    if f_pattern_correlation:
        # for a climatology with 12 values, a significant level of p<0.05
        # is reached , when correlation is larger than 0.58
        if PC_plot.get_n() > 0:
            PC_plot.plot(cmap='YlOrRd', interpolation='nearest',
                         vmin=0.5, vmax=1., nclasses=10,
                         monthly_clim_ticks=True)
            PC_plot.figure.suptitle('Pattern correlation: ' + obs_orig.label.upper())

            report.figure(PC_plot.figure, caption='Pattern correlation for ' + obs_orig.label.upper())
            report.newpage()

            hstackfile = report.outdir + 'Climate_mean_timeseries_correlations_' + obs_type.upper() + '_' + obs_orig.label.upper().replace(' ', '') + '.png'
            PC_plot.figure.savefig(hstackfile, dpi=200)

            plt.close(PC_plot.figure.number)

            del PC_plot

    del obs_monthly

    if f_reichler is True:
        sys.stdout.write('\n *** Reichler plot.\n')
        f_reich = Rplot.bar(title='relative model error: %s' % obs_type.upper())
        report.figure(f_reich, caption='Relative model performance for ' + obs_type.upper())
        report.newpage()
        plt.close(f_reich.number)
        del Rplot

    sys.stdout.write('\n *** Processing finished. \n')

#=======================================================================
# GENERIC - end
#=======================================================================


#=======================================================================
# VEGETATION COVER FRACTION -- begin
#=======================================================================

def phenology_faPAR_analysis(model_list, GP=None, shift_lon=None, use_basemap=False, report=None):
    """
    Analysis of vegetation phenology

    @param model_list: list of model C{Data} objects
    @param GP: Gleckler plot instance
    @param shift_lon: shift data in longitude direction
    @param use_basemap: use basemap for the analysis
    @param report: instance of Report

    Reference:
    Dahlke, C., Loew, A. & Reick, C., 2012. Robust identification of global greening phase patterns from remote
           sensing vegetation products. Journal of Climate, p.120726140719003.
           Available at: http://journals.ametsoc.org/doi/abs/10.1175/JCLI-D-11-00319.1 [Accessed December 6, 2012].

    """

    #/// OPTIONS
    f_execute = True  # execute scripts

    #script names
    template1 = './external/phenology_benchmarking/Greening_Phase_Analysis_I.m'
    template2 = './external/phenology_benchmarking/Greening_Phase_Analysis_II.m'
    template3 = './external/phenology_benchmarking/Greening_Phase_Analysis_III.m'
    template4 = './external/phenology_benchmarking/Greening_Phase_Analysis_IV.m'

    if GP is None:
        GP = GlecklerPlot()

    for model in model_list:
        print '*** PHENOLOGY analysis for model: ' + model.name

        fapar_data = model.variables['phenology_faPAR']  # data object for phenology variable
        snow_data = model.variables['snow']             # data object for snow variable

        # output directory for analysis results of current model
        outdir = os.getcwd() + '/output/GPA-01-' + model.name.replace(' ', '')

        # directory where model simulations are performed and templates are copied to
        rundir = './output/tmp_' + model.name.replace(' ', '') + '/'

        # Gleckler plot
        GP.add_model(model.name)

        # file and variable names ///
        data_file = fapar_data.filename
        varname = fapar_data.varname

        snowfilename = snow_data.filename
        snowvar = snow_data.varname

        #//////////////////////////////////////
        # GREENING PHASE ANALYSIS - STEP1
        #//////////////////////////////////////
        tags = [{'tag': '<STARTYEAR>', 'value': '1995'}, {'tag': '<STOPYEAR>', 'value': '2005'},
                {'tag': '<OUTDIR>', 'value': outdir},
                {'tag': '<FFTFIGNAME>', 'value': 'FFT-Mask-' + model.name.replace(' ', '')},
                {'tag': '<INPUTDATAFILE>', 'value': data_file}, {'tag': '<DATAVARNAME>', 'value': varname},
                {'tag': '<FFTMASKFILE>', 'value': outdir + '/fft_mask.mat'}]
        E = ExternalAnalysis('matlab -nosplash -nodesktop -r <INPUTFILE>', template1, tags, options=',quit',
                             output_directory=rundir)  # temporary scripts are stored in directories that have same name as model
        E.run(execute=f_execute, remove_extension=True)

        #//////////////////////////////////////
        # GREENING PHASE ANALYSIS - STEP2
        #//////////////////////////////////////
        tags.append({'tag': '<INPUTSNOWFILE>', 'value': snowfilename})
        tags.append({'tag': '<SNOWVARNAME>', 'value': snowvar})
        E = ExternalAnalysis('matlab -nosplash -nodesktop -r <INPUTFILE>', template2, tags, options=',quit',
                             output_directory=rundir)
        E.run(execute=f_execute, remove_extension=True)

        #//////////////////////////////////////
        # GREENING PHASE ANALYSIS - STEP3
        #//////////////////////////////////////
        tags.append({'tag': '<INPUTDIRECTORY>', 'value': outdir + '/'})
        tags.append(
            {'tag': '<SENSORMASKFILE>', 'value': os.getcwd() + '/external/phenology_benchmarking/sensor_mask.mat'})
        tags.append({'tag': '<RESULTDIR_AVHRR>',
                     'value': '/net/nas2/export/eo/workspace/m300028/GPA/sensors/AVH_T63'})  # @todo this needs to compe from POOL SEP !!!!
        tags.append(
            {'tag': '<RESULTDIR_SEAWIFS>', 'value': '/net/nas2/export/eo/workspace/m300028/GPA/sensors/SEA_T63'})
        tags.append(
            {'tag': '<RESULTDIR_CYCLOPES>', 'value': '/net/nas2/export/eo/workspace/m300028/GPA/sensors/CYC_T63'})
        tags.append({'tag': '<RESULTDIR_MODIS>', 'value': '/net/nas2/export/eo/workspace/m300028/GPA/sensors/MCD_T63'})
        E = ExternalAnalysis('matlab -nosplash -nodesktop -r <INPUTFILE>', template3, tags, options=',quit',
                             output_directory=rundir)
        E.run(execute=f_execute, remove_extension=True)

        #//////////////////////////////////////
        # GREENING PHASE ANALYSIS - STEP4
        #//////////////////////////////////////
        tags.append({'tag': '<FIG1CAPTION>', 'value': 'Fig1_FFT_Mask_Evergreen_Overview'})
        tags.append({'tag': '<FIG2CAPTION>', 'value': 'Fig2_GPAII_Results'})
        tags.append({'tag': '<FIG3CAPTION>', 'value': 'Fig3_GPAIII_Shifts_between_Model_Sensors'})
        tags.append({'tag': '<FIG4CAPTION>', 'value': 'Fig4_Time_series_from_various_biomes'})
        tags.append({'tag': '<RUNDIR>', 'value': rundir})
        E = ExternalAnalysis('matlab -nosplash -nodesktop -r <INPUTFILE>', template4, tags, options=',quit',
                             output_directory=rundir)
        E.run(execute=f_execute, remove_extension=True)

        #/// Gleckler plot ///
        #~ e2a = GP.calc_index(gpcp,model_data,model,'pheno_faPAR')
        e2a = 0.  # @todo
        GP.add_data('pheno_faPAR', model.name, e2a, pos=1)


def grass_fraction_analysis(model_list):
    #use same analysis script as for trees, but with different argument
    tree_fraction_analysis(model_list, pft='grass')


def tree_fraction_analysis(model_list, pft='tree'):
    def fraction2netcdf(pft):
        raise ValueError('Nio not supported any more! This routine needs recoding first!')
        filename = '/home/m300028/shared/dev/svn/trstools-0.0.1/lib/python/pyCMBS/framework/external/vegetation_benchmarking/VEGETATION_COVER_BENCHMARKING/example/' + pft + '_05.dat'
        #save 0.5 degree data to netCDF file
        t = pl.loadtxt(filename)
        outname = filename[:-4] + '.nc'
        if os.path.exists(outname):
            os.remove(outname)
        F = Nio.open_file(outname, 'w')
        F.create_dimension('lat', t.shape[0])
        F.create_dimension('lon', t.shape[1])
        var = F.create_variable(pft + '_fraction', 'd', ('lat', 'lon'))
        lat = F.create_variable('lat', 'd', ('lat',))
        lon = F.create_variable('lon', 'd', ('lon',))
        lon.standard_name = "grid_longitude"
        lon.units = "degrees"
        lon.axis = "X"
        lat.standard_name = "grid_latitude"
        lat.units = "degrees"
        lat.axis = "Y"
        var._FillValue = -99.
        var.assign_value(t)
        lat.assign_value(
            np.linspace(90. - 0.25, -90. + 0.25, t.shape[0]))  # todo: center coordinates or corner coordinates?
        lon.assign_value(np.linspace(-180. + 0.25, 180. - 0.25, t.shape[1]))

        F.close()

        return outname

    #//// load tree fraction observations ////
    #1) convert to netCDF
    fraction_file = fraction2netcdf(pft)

    #2) remap to T63
    y1 = '2001-01-01'
    y2 = '2001-12-31'
    cdo = pyCDO(fraction_file, y1, y2)
    t63_file = cdo.remap(method='remapcon')

    #3) load data
    ls_mask = get_T63_landseamask()
    hansen = Data(t63_file, pft + '_fraction', read=True,
                  label='MODIS VCF ' + pft + ' fraction', unit='-',
                  lat_name='lat', lon_name='lon', shift_lon=shift_lon,
                  mask=ls_mask.data.data)

    #//// PERFORM ANALYSIS ///
    vmin = 0.
    vmax = 1.
    for model in model_list:

        model_data = model.variables[pft]

        if model_data.data.shape != hansen.data.shape:
            print('WARNING Inconsistent geometries for GPCP')
            print model_data.data.shape
            print hansen.data.shape

        dmin = -1.
        dmax = 1.
        dif = map_difference(model_data, hansen, vmin=vmin, vmax=vmax,
                             dmin=dmin, dmax=dmax,
                             use_basemap=use_basemap,
                             cticks=[0., 0.25, 0.5, 0.75, 1.])

        #/// ZONAL STATISTICS
        #--- append zonal plot to difference map
        ax1 = dif.get_axes()[0]
        ax2 = dif.get_axes()[1]
        ax3 = dif.get_axes()[2]

        #create net axis for zonal plot
        #http://old.nabble.com/manual-placement-of-a-colorbar-td28112662.html
        divider1 = make_axes_locatable(ax1)
        zax1 = divider1.new_horizontal("50%", pad=0.05, axes_class=maxes.Axes, pack_start=True)
        dif.add_axes(zax1)

        divider2 = make_axes_locatable(ax2)
        zax2 = divider2.new_horizontal("50%", pad=0.05, axes_class=maxes.Axes, pack_start=True)
        dif.add_axes(zax2)

        divider3 = make_axes_locatable(ax3)
        zax3 = divider3.new_horizontal("50%", pad=0.05, axes_class=maxes.Axes, pack_start=True)
        dif.add_axes(zax3)

        #--- calculate zonal statistics and plot
        zon1 = ZonalPlot(ax=zax1)
        zon1.plot(model_data, xlim=[vmin, vmax])
        zon2 = ZonalPlot(ax=zax2)
        zon2.plot(hansen, xlim=[vmin, vmax])
        zon3 = ZonalPlot(ax=zax3)
        zon3.plot(model_data.sub(hansen))
        zon3.ax.plot([0., 0.], zon3.ax.get_ylim(), color='k')

        #--- calculate RMSE statistics etc.
        ES = CorrelationAnalysis(model_data, hansen)
        ES.do_analysis()


#=======================================================================
# VEGETATION COVER FRACTION -- end
#=======================================================================


#=======================================================================
# SURFACE UPWARD FLUX -- begin
#=======================================================================
def surface_upward_flux_analysis(model_list, interval='season', GP=None,
                                 shift_lon=False, use_basemap=False,
                                 report=None, plot_options=None,
                                 regions=None):
    main_analysis(model_list, interval=interval, GP=GP,
                  shift_lon=shift_lon,
                  use_basemap=use_basemap, report=report,
                  plot_options=plot_options,
                  actvar='surface_upward_flux', regions=regions)

#=======================================================================
# SURFACE UPWARD FLUX -- end
#=======================================================================


#=======================================================================
# ALBEDO -- begin
#=======================================================================
def albedo_analysis_vis(model_list, interval='season', GP=None,
                        shift_lon=False, use_basemap=False,
                        report=None,
                        plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP,
                  shift_lon=shift_lon, use_basemap=use_basemap,
                  report=report,
                  plot_options=plot_options, actvar='albedo_vis', regions=regions)


def albedo_analysis_nir(model_list, interval='season', GP=None,
                        shift_lon=False, use_basemap=False,
                        report=None,
                        plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP,
                  shift_lon=shift_lon, use_basemap=use_basemap,
                  report=report,
                  plot_options=plot_options, actvar='albedo_nir',
                  regions=regions)


def albedo_analysis(model_list, interval='season', GP=None,
                    shift_lon=False, use_basemap=False, report=None,
                    plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP,
                  shift_lon=shift_lon, use_basemap=use_basemap,
                  report=report, plot_options=plot_options,
                  actvar='albedo', regions=regions)


def xxxxxalbedo_analysis(model_list, GP=None, shift_lon=None, use_basemap=False, report=None, interval='season',
                         plot_options=None, regions=None):
    if shift_lon is None:
        raise ValueError('You need to specify shift_lon option!')
    if use_basemap is None:
        raise ValueError('You need to specify use_basemap option!')
    if report is None:
        raise ValueError('You need to specify report option!')

    print
    print '************************************************************'
    print '* BEGIN ALBEDO analysis ...'
    print '************************************************************'

    report.section('Surface albedo')

    # Figures
    fG = plt.figure()
    axg = fG.add_subplot(211)
    axg1 = fG.add_subplot(212)

    # GlobalMean plot
    GM = GlobalMeanPlot(ax=axg, ax1=axg1, climatology=True)

    # MODIS white sky albedo
    report.subsection('MODIS WSA')
    report.write('MODIS albedo is based on the MODIS white-sky \
                    albedo product. Snow covered areas remain in the \
                    data product, but all pixels flagged as invalid \
                    was discarded.')
    generic_analysis(plot_options, model_list, 'albedo', 'MODIS',
                     GP=GP, GM=GM, report=report,
                     use_basemap=use_basemap, shift_lon=shift_lon,
                     interval=interval, regions=regions)

    # AVHRR GAC SAL black sky albedo
    report.subsection('AVHRR CLARASAL')
    report.write('AVHRR SAL is a black-sky albedo product generated in \
                    the frame of the CM-SAF')
    generic_analysis(plot_options, model_list, 'albedo', 'CLARASAL',
                     GP=GP, GM=GM, report=report,
                     use_basemap=use_basemap, shift_lon=shift_lon,
                     interval=interval, regions=regions)

    # climatological means
    fGa = GM.plot_mean_result(dt=5.,
                              colors={'observations': 'blue', 'models': 'red'})
    fGb = GM.plot_mean_result(dt=0.1,
                              colors={'observations': 'blue', 'models': 'red'},
                              plot_clim=True)

    report.figure(fG, caption='Global means for land surface albedo', bbox_inches=None)
    report.figure(fGa, caption='Global means for land surface albedo (summary)', bbox_inches=None)
    report.figure(fGb, caption='Global means for land surface albedo (climatological summary)', bbox_inches=None)

    pl.close(fGa.number)
    pl.close(fGb.number)
    pl.close(fG.number)
    del fG, fGa, fGb

    print('************************************************************')
    print('* END ALBEDO analysis ...')
    print('************************************************************')
    print('')

    del GM

#=======================================================================
# ALBEDO -- end
#=======================================================================

#=======================================================================
# TEMPERATURE -- begin
#=======================================================================


def temperature_analysis(model_list, interval='season', GP=None,
                         shift_lon=False, use_basemap=False, report=None,
                         plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP, shift_lon=shift_lon,
                  use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='temperature',
                  regions=regions)

#=======================================================================
# TEMPERATURE -- end
#=======================================================================


#=======================================================================
# MAIN analysis
#=======================================================================

def main_analysis(model_list, interval='season', GP=None, shift_lon=False,
                  use_basemap=False, report=None, plot_options=None,
                  actvar=None, regions=None, sectionheader=''):
    """
    model_list : xxxxxxxxxxxx
        xxxxxxxxxxxxxxxxxxxxxx
    interval : str
        specifies the main analysis interval ['monthly','season']
    GP : GlecklerPlot
        instance of GlecklerPlot class; default=None, then new instance
        is generated

    actvar: variable to analyze
    """

    if interval not in ['monthly', 'season']:
        raise ValueError('Invalid interval option! %s' % interval)
    if shift_lon is None:
        raise ValueError('You need to specify shift_lon option!')
    if use_basemap is None:
        raise ValueError('You need to specify use_basemap option!')
    if report is None:
        raise ValueError('You need to specify report option!')
    if plot_options is None:
        raise ValueError('No plot options are specified. No further processing possible!')
    if actvar is None:
        raise ValueError('No name for actual variable specified! Please correct!')
    if GP is None:
        raise ValueError('Gleckler plot not specified!')

    thevar = actvar
    if thevar not in plot_options.options.keys():
        raise ValueError('The variable is not existing in the plot_options: %s' % thevar)
    thelabel = plot_options.options[thevar]['OPTIONS']['label']
    thelabel = thelabel.upper()

    print('')
    print('************************************************************')
    print('* BEGIN ' + thelabel + ' analysis ...')
    print('************************************************************')

    # section header for current variable
    report.section(thelabel)
    if sectionheader != '':
        report.write(sectionheader)

    # figure
    fG = plt.figure()
    axg = fG.add_subplot(211)
    axg1 = fG.add_subplot(212)
    GM = GlobalMeanPlot(ax=axg, ax1=axg1, climatology=True)

    GM_HT_clim = HstackTimeseries()  # alternative way to plot global mean timeseries

    if thevar in plot_options.options.keys():
        #do analysis for all observational datasets specified in INI file
        for k in plot_options.options[thevar].keys():
            if k == 'OPTIONS':
                continue
            else:
                print 'IN MAIN ANALYSIS: ', thevar, k
                if plot_options.options[thevar][k]['add_to_report']:
                    report.subsection(k)
                    generic_analysis(plot_options, model_list, thevar, k, GP=GP, GM=GM, report=report,
                                     use_basemap=use_basemap, shift_lon=shift_lon, interval=interval, regions=regions, GM_HT_clim=GM_HT_clim)
    else:
        raise ValueError('Can not do analysis for %s  for some reason! Check config and plot option files!' % thelabel)

    # global mean plots
    # a) standard way to plot it
    report.figure(fG, caption='Global means for ' + thelabel, bbox_inches=None)
    fGa = GM.plot_mean_result(dt=5., colors={'observations': 'blue', 'models': 'red'})
    fGb = GM.plot_mean_result(dt=0., colors={'observations': 'blue', 'models': 'red'}, plot_clim=True)

    report.figure(fGa,
                  caption='Global means for ' + thelabel + ' (summary); areas indicate $\pm 1 \sigma$ as derived from'
                                                           ' the ensemble of models or observations', bbox_inches=None)
    report.figure(fGb, caption='Global means for ' + thelabel + ' (summary climatology)', bbox_inches=None)

    plt.close(fG.number)
    plt.close(fGa.number)
    plt.close(fGb.number)

    #b) alternative way to plot it
    if GM_HT_clim.get_n() > 0:
        GM_HT_clim.plot(cmap='jet', interpolation='nearest', vmin=plot_options.options[thevar]['OPTIONS']['cmin'], vmax=plot_options.options[thevar]['OPTIONS']['cmax'], nclasses=15, monthly_clim_ticks=True)
        report.figure(GM_HT_clim.figure, caption='Global means climatology for ' + thelabel, bbox_inches=None)

        hstackfile = report.outdir + 'Climate_mean_timeseries_' + thevar.upper() + '.png'
        GM_HT_clim.figure.savefig(hstackfile, dpi=200)

        plt.close(GM_HT_clim.figure.number)
        del GM_HT_clim

    del GM, fG, fGa, fGb

    print('')
    print('************************************************************')
    print('* END ' + thelabel + ' analysis ...')
    print('************************************************************')


#=======================================================================
# SIS -- begin
#=======================================================================
def sis_analysis(model_list, interval='season', GP=None,
                 shift_lon=None, use_basemap=None, report=None,
                 plot_options=None, regions=None):
    main_analysis(model_list, interval=interval, GP=GP,
                  shift_lon=shift_lon,
                  use_basemap=use_basemap, report=report,
                  plot_options=plot_options, actvar='sis',
                  regions=regions)

#=======================================================================
# SIS -- end
#=======================================================================


#=======================================================================
# Beer -- begin
#=======================================================================

def beer_analysis(model_list, GP=None, shift_lon=None, use_basemap=False, report=None, interval='season',
                  plot_options=None):
    if shift_lon is None:
        raise ValueError('You need to specify shift_lon option!')
    if use_basemap is None:
        raise ValueError('You need to specify use_basemap option!')
    if report is None:
        raise ValueError('You need to specify report option!')

    print
    print '************************************************************'
    print '* BEGIN Beer analysis ...'
    print '************************************************************'

    report.section('GPP')

    local_plot_options = plot_options.options["gpp"]
    cticks = (0.0, 300.0, 600.0, 900.0, 1200.0, 1500.0, 1800.0, 2100.0, 2400.0, 2700.0)

    fG = plt.figure()
    ax = fG.add_subplot(111,
                        xlabel='lat',
                        ylabel='GPP [gC m-2 a-1]',
                        xlim=[90.0, -90.0],
                        xticks=[90, 60, 30, 0, -30, -60, -90])

    for k in plot_options.options['gpp'].keys():
        if k == 'BEER':
            f_beer = figure()
            ax_Beer = f_beer.add_subplot(111)
            ls_mask = get_T63_landseamask(shift_lon)

            obs_raw = local_plot_options['BEER']['obs_file']
            obs_var = local_plot_options['BEER']['obs_var']
            GPP_BEER = Data(obs_raw, obs_var, read=True, lat_name='lat', lon_name='lon', label='GPP Beer_etal_2010',
                            mask=ls_mask.data.data, unit='gC m-2 a-1')
            Beer_zonal = GPP_BEER.get_zonal_mean(return_object=True)
            ax.plot(Beer_zonal.lat, Beer_zonal.data.data, 'k', label='Beer etal T63')
            map_plot(GPP_BEER, title='Beer etal T63', vmin=0.0, vmax=3000.0, use_basemap=use_basemap, cticks=cticks,
                     show_zonal=True, ax=ax_Beer)

            report.subsection('Beer')
            report.figure(f_beer, caption='Beer etal 2010', bbox_inches=None)

        if k == 'OPTIONS':
            for model in model_list:
                if model.name != 'mean-model':
                    f_model = figure()
                    ax_model = f_model.add_subplot(111)
                    obs_mon_file = get_temporary_directory()
                    f = obs_mon_file + model.experiment + '_' + str(model.start_time)[0:4] + '-' + str(model.stop_time)[
                        0:4] + '_ymonmean.nc'
                    GPP_Model = Data4D(f, 'var167', read=True, lat_name='lat', lon_name='lon',
                                       label=model.name + '(' + str(model.start_time)[0:4] + '-' + str(model.stop_time)[0:4] + ')',
                                       unit='gC m-2 a-1',
                                       scale_factor=3600. * 24. * 30. / 0.083).sum_data4D()

                    GPP_Model2 = GPP_Model.timmean(return_object=True)
                    GPP_Model2.data.mask[less(GPP_Model2.data, 0.1)] = True
                    map_plot(GPP_Model2, title=model.name, vmin=0.0, vmax=3000.0, use_basemap=use_basemap,
                             cticks=cticks, show_zonal=True, ax=ax_model)
                    JSBACH_zonal = GPP_Model2.get_zonal_mean(return_object=True)
                    ax.plot(JSBACH_zonal.lat, JSBACH_zonal.data.data,
                            label=model.name + '(' + str(model.start_time)[0:4] + '-' + str(model.stop_time)[0:4] + ')')
                    report.subsection('Model (' + model.name + ')')
                    report.figure(f_model,
                                  caption=model.name + '(' + str(model.start_time)[0:4] + '-' + str(model.stop_time)[
                                      0:4] + ')',
                                  bbox_inches=None)

    fontP = FontProperties()
    fontP.set_size('xx-small')
    ax.legend(prop=fontP, frameon=True, labelspacing=0.2, loc='upper left')

    report.subsection('Zonal')
    report.figure(fG, caption='Zonal mean GPP for model and Beer from ' + '(' + str(model.start_time)[0:4] + '-' + str(
        model.stop_time)[0:4] + ')', bbox_inches=None)

    print '************************************************************'
    print '* END Beer analysis ...'
    print '************************************************************'
    print

    del f_model
    del fG


def time_series_regional_analysis(x, y, msk):
    """
    This is a dummy routine to perform a comparison of timeseries on a regional basis
    The routine does
    1) apply common mask; prerequesite is that both datasets have same geometry
    2) calculate timeseries
    3) plots results
    """

    if x.shape != y.shape:
        raise ValueError('Datasets have not the same geometry')

    X = x.copy()
    Y = y.copy()

    #--- mask data as invalid ---
    invalid = x.data.mask | y.data.mask  # mask as invalid if one of the datasets is invalid
    X.data.mask[invalid] = True
    Y.data.mask[invalid] = True

    X.weighting_type = 'all'  # whole globe for weighting
    Y.weighting_type = 'all'

    L = LinePlot(title='mytitle')

    for v in np.unique(msk):  # analysis for all unique values in mask
        # now do analysis for each region ---
        # 1) calculate mask
        m = msk == v
        tmpx = X.copy()
        tmpx._apply_mask(m)
        tmpy = Y.copy()
        tmpy._apply_mask(m)

        # 2) plot results
        L.plot(tmpx, label='X region ' + str(int(v)).zfill(4))  # calculates automatically the fldmean()
        L.plot(tmpy, label='X region ' + str(int(v)).zfill(4))

        del tmpx, tmpy
    return L.figure
